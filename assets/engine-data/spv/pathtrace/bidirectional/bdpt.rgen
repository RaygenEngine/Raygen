#version 460
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_ray_tracing : require
// TODO:
#define RAY
#include "global.glsl"

#include "random.glsl"
#include "sampling.glsl"
#include "surface.glsl"

struct PathVertex {
	vec3 position;
	vec3 normal;
	vec3 throughput; // attenuated light value
};

struct hitPayload
{
	vec3 origin; // next ray stuff
	vec3 direction;
	vec3 normal;
	vec3 throughput;

	int hitType; 
	// 0 - continue
	// 1 - break;
	uint seed;
};

struct mergePayload
{
	vec3 target;
	vec3 wi;

	vec3 connectionFactor;

	int visible;
};

layout(push_constant) uniform PC
{
	// WIP: max length path
	int bounces;
	int frame;
	int pointlightCount;
	int spotlightCount;
	int dirlightCount;
	int quadlightCount;
};

layout(set = 0, binding = 0, rgba32f) uniform image2D image;
layout(set = 0, binding = 1, rgba32f) uniform image2D progressive;
layout(set = 1, binding = 0) uniform UBO_Camera { Camera cam; };
layout(set = 2, binding = 0) uniform accelerationStructureEXT topLevelAs;
layout(set = 7, binding = 0, std430) readonly buffer Quadlights { Quadlight light[]; } quadlights;

layout(location = 0) rayPayloadEXT hitPayload prd;
layout(location = 1) rayPayloadEXT mergePayload mprd;

void TraceCameraRay() {
    uint  rayFlags =  gl_RayFlagsCullFrontFacingTrianglesEXT;
    float tMin     = 0.001;
    float tMax     = 10000.0;

	traceRayEXT(topLevelAs,     // acceleration structure
				rayFlags,       // rayFlags
				0xFF,           // cullMask - none
				0,              // sbtRecordOffset
				0,              // sbtRecordStride
				0,              // missIndex
				prd.origin,     // ray origin
				tMin,           // ray min range
				prd.direction,  // ray direction
				tMax,           // ray max range
				0               // payload (location = 0)
	);
}

void TraceLightRay() {
    uint  rayFlags =  gl_RayFlagsCullFrontFacingTrianglesEXT;
    float tMin     = 0.001;
    float tMax     = 10000.0;

	traceRayEXT(topLevelAs,     // acceleration structure
				rayFlags,       // rayFlags
				0xFD,           // cullMask - quadlights WIP: if we hit light again, end path
				2,              // sbtRecordOffset
				0,              // sbtRecordStride
				1,              // missIndex
				prd.origin,     // ray origin
				tMin,           // ray min range
				prd.direction,  // ray direction
				tMax,           // ray max range
				0               // payload (location = 0)
	);
}

bool PathMergeRay(PathVertex pstart, PathVertex ptarget, PathVertex pnext, inout vec3 connectionFactor) {
    uint  rayFlags =  gl_RayFlagsCullFrontFacingTrianglesEXT;
    float tMin     = 0.001;
    float tMax     = 10000.0;

	vec3 direction = normalize(ptarget.position - pstart.position);

	// bias offset based on normal and direction. 
	float k = dot(direction, pstart.normal);
	float sign = sign(k) + (1.0 - abs(sign(k))); 

	// always offset above surface
	vec3 origin = pstart.position;//WIP: + sign * direction * BIAS; 
	
	mprd.target = ptarget.position;
	mprd.wi = normalize(pnext.position - ptarget.position); // wo\ /wi

	traceRayEXT(topLevelAs,     // acceleration structure
				rayFlags,       // rayFlags
				0xFF,           // cullMask - none
				3,              // sbtRecordOffset
				0,              // sbtRecordStride
				2,              // missIndex
				origin,         // ray origin
				tMin,           // ray min range
				direction,      // ray direction
				tMax,           // ray max range
				1               // payload (location = 1)
	);

	connectionFactor = mprd.connectionFactor;

	return mprd.visible == 1;
}

bool IsValidPixel(vec3 pLens, vec3 pWorld, out ivec2 pixel) {

	vec4 pView = cam.view * vec4(pWorld, 1.0f);
    vec4 pLensLocal = cam.view * vec4(pLens, 1.0f);

    // pWorld is behind camera lens
    if (pView.z > 0.0f) {
        return false;
    }
    vec4 dir = vec4(pView - pLensLocal);
    // pWorld is on the plane of of lens, it won't be in the screen
    if (abs(dir.z) < BIAS) {
        return false;
    }
    vec4 pFocus = pLensLocal + (1.f/*WIP desc set mFocalDistance*/ / dir.z) * dir;
    vec4 pNDC = cam.proj * pFocus;
    pNDC /= pNDC.w;
    float screenX = (pNDC.x + 1.0f) * 0.5f * gl_LaunchSizeEXT.x;
    float screenY = (1.0f - pNDC.y) * 0.5f * gl_LaunchSizeEXT.y;

	// WIP:
	pixel = ivec2(ceil(screenX), ceil(screenY));

	return //pixel.x == gl_LaunchIDEXT.x && pixel.y == gl_LaunchIDEXT.y;
	       (pixel.x >= 0 && pixel.x < gl_LaunchSizeEXT.x &&
	        pixel.y >= 0 && pixel.y < gl_LaunchSizeEXT.y);
}

float evalWe(vec3 pCamera, vec3 pWorld) {

	vec4 pView = cam.view * vec4(pWorld, 1.0f);
	vec4 pLensLocal = cam.view * vec4(pCamera, 1.0f);
	vec4 dir = pView - pLensLocal;
	vec4 pFocus = pLensLocal + (/*cam.focalLength*/1.0 / dir.z) * dir; 
    vec3 lensToFilm = pFocus.xyz - pLensLocal.xyz;

    float lensToFilmDistance2 = dot(lensToFilm, lensToFilm);
    float cosTheta = normalize(lensToFilm).z;
    float G = cosTheta * cosTheta / lensToFilmDistance2;
	float pdf_lens = 1;
	float pdf_film = 1.0 / cam.filmArea;
    float We = pdf_lens * pdf_film / G; // see importance...
    return We;
}

vec3 evalLe(Quadlight ql, vec3 direction) {
    
    return dot(ql.normal, direction) < BIAS ? vec3(0) : ql.intensity * ql.color;
}

void main() {

	// same as light sample
	PathVertex cameraVertices[1];

	vec3 pCamera = cam.position; // pinhole

	// on the lens - pinhole
	cameraVertices[0].position = pCamera;
	cameraVertices[0].normal = -vec3(cam.view[0][2], cam.view[1][2], cam.view[2][2]);
	cameraVertices[0].throughput = vec3(1.0);

	// CAMERA PATH WIP:
	{
//		float r1 = rand(prd.seed);
//		float r2 = rand(prd.seed);
//
//		vec2 subpixel_jitter = frame == 0 ? vec2(0.0f, 0.0f) : vec2(r1 - 0.5f, r2 - 0.5f);
//
//		const vec2 pixelCenter = vec2(gl_LaunchIDEXT.xy) + vec2(0.5) + subpixel_jitter;
//		const vec2 inUV        = pixelCenter / vec2(gl_LaunchSizeEXT.xy);
//		vec2       d           = inUV * 2.0 - 1.0;
//
//		vec4 origin    = cam.viewInv * vec4(0, 0, 0, 1);
//		vec4 target    = cam.projInv * vec4(d.x, d.y, 1, 1);
//		vec4 direction = cam.viewInv * vec4(target.xyz, 0);
//
//		// pixelWidth * pixelHeight SMATH:
//		float pdf_pixelArea = 1.0 / (1.0 * 1.0);
	}

#define maxLightPath 15

	// picked light
	Quadlight ql;
	vec3 pLight;


	int lightVertex;
	PathVertex lightVertices[maxLightPath];
	
	prd.seed = tea16(gl_LaunchIDEXT.y * gl_LaunchSizeEXT.x + gl_LaunchIDEXT.x, frame);
			
	// LIGHT PATH
	{
		// pick one of the lights
		int totalLights = quadlightCount;
		float u = rand(prd.seed);
		int i = int(floor(u * totalLights));

		ql = quadlights.light[i];

		float pdf_pickLight = 1.0 / float(totalLights); 
		float pdf_lightArea = 1.0 / (ql.width * ql.height);
		
		vec2 u2 = rand2(prd.seed) * 2 - 1;
		u2.x *= ql.width / 2.f;
		u2.y *= ql.height / 2.f;

		// pick origin on surface
		pLight = ql.center + u2.x * ql.right + u2.y * ql.up;

		prd.origin = pLight;
		prd.normal = ql.normal;

		// on surface of light
		lightVertices[0].position = prd.origin;
		lightVertices[0].normal = prd.normal;
		lightVertices[0].throughput = vec3(1.0) / (pdf_pickLight * pdf_lightArea);

		// random hemisphere direction 
		u2 = rand2(prd.seed);

		vec3 v = uniformSampleHemisphere(u2); // WIP: biased at edges (see quadlight bias)
		prd.direction =

		vec3(ql.right.x * v.x + ql.up.x * v.y + ql.normal.x * v.z,
			 ql.right.y * v.x + ql.up.y * v.y + ql.normal.y * v.z,
			 ql.right.z * v.x + ql.up.z * v.y + ql.normal.z * v.z);

		// projection solid angle form
		float pdf_lightDirection = uniformHemispherePdf() / absdot(ql.normal, prd.direction);
		
		vec3 throughput = lightVertices[0].throughput / pdf_lightDirection;

		lightVertex = 1;
		for(;lightVertex < maxLightPath; ++lightVertex) {
			
			lightVertices[lightVertex].throughput = throughput;

			TraceLightRay(); 

			if(prd.hitType == 1) {
				break;
			}

			lightVertices[lightVertex].position = prd.origin;
			lightVertices[lightVertex].normal = prd.normal;

			throughput *= prd.throughput;
		}
	}


	if(frame == 0)
	{
		imageStore(image, ivec2(gl_LaunchIDEXT.xy), vec4(0));
		imageStore(progressive, ivec2(gl_LaunchIDEXT.xy), vec4(0));
		return;
	}

	// merge t = 1 s = 1 - ie merge 
	for (int s = 1; s <= lightVertex; ++s) {

		// merge light vertex directly with camera lens vertex
		const PathVertex lv = lightVertices[s - 1]; // light vertex
		const PathVertex pv = s > 1 ? lightVertices[s - 2] : lv; // previous light vertex
		const PathVertex cv = cameraVertices[0]; // camera vertex

		ivec2 pixel;
		if(!IsValidPixel(cv.position, lv.position, pixel)) {
			continue; // WIP:
		}

		vec3 connectionFactor = vec3(1);
		if(!PathMergeRay(cv, lv, pv, connectionFactor)) {
			continue; // WIP:
		}

		vec3 wo = normalize(cv.position - lv.position);
		float dist = distance(cv.position, lv.position);
		// G between end points between light path and eye path
		float G = absdot(lv.normal, wo) * absdot(cv.normal, wo) / (dist * dist);
		vec3 fsL;
		if(s > 1) {
			fsL = connectionFactor * evalLe(ql, normalize(lv.position - pLight));

		}
		else {
			fsL = evalLe(ql, normalize(lv.position - pLight));
		}
		float fsE = evalWe(cv.position, lv.position);
		vec3 color = fsL * lv.throughput * G * cv.throughput * fsE;

		vec4 data = imageLoad(image, pixel);
		
		if(data.a > 0) {
			float a = 1.0f / float(data.a);
			color = mix(data.xyz, color, a);
		}

		vec4 val = vec4(color, data.a + 1.f);
		imageStore(image, pixel, val); // WIP: race conditions
	}

	//imageStore(image, pixel, vec4(color, 1.f));

//	color /= float(lightVertex);

//	PathVertex plv = lightVertices[2]; 
//	PathVertex lv = lightVertices[3]; 
//	PathVertex cv = cameraVertices[0];
//
//	if(!IsValidPixel(cv.position, lv.position, pixel)) {
//		return; // WIP:
//	}
//
//	vec3 connectionFactor = vec3(1);
//	if(!PathMergeRay(cv, lv, plv, connectionFactor)) {
//		return; // WIP:
//	}
//
//	vec3 wo = normalize(cv.position - lv.position);
//	float dist = distance(cv.position, lv.position);
//	// G between end points between light path and eye path
//	float G = absdot(lv.normal, wo) * absdot(cv.normal, wo) / (dist * dist);
//	vec3 fsL = evalLe(ql, normalize(lv.position - pLight));
//	float fsE = evalWe(cv.position, lv.position);
//	color = fsL * lv.throughput * connectionFactor * G * cv.throughput * fsE;
	
//	if(frame > 0)
//	{
//		float a = 1.0f / float(frame);
//		vec3 old_color = imageLoad(progressive, pixel).xyz;
//		color = mix(old_color, color, a);
//	}
//	
//	imageStore(image, pixel, vec4(color, 1.f));
//	imageStore(progressive, pixel, vec4(color, 1.f));
}
