#version 460
#extension GL_GOOGLE_include_directive : enable

#include "global.glsl"
#include "onb.glsl"
#include "bsdf.glsl"
#include "hammersley.glsl"
#include "sampling.glsl"

layout (local_size_x = 32, local_size_y = 32) in;

layout(set = 0, binding = 0, rgba32f) uniform imageCube irradianceCube;
layout(set = 1, binding = 0) uniform samplerCube envmapSampler;

mat4 lookAtRH(vec3 eye, vec3 center, vec3 up)
{
	vec3 f = normalize(center - eye);
	vec3 s = normalize(cross(f, up));
	vec3 u = cross(s, f);

	mat4 Result = mat4(1);
	Result[0][0] = s.x;
	Result[1][0] = s.y;
	Result[2][0] = s.z;
	Result[0][1] = u.x;
	Result[1][1] = u.y;
	Result[2][1] = u.z;
	Result[0][2] =-f.x;
	Result[1][2] =-f.y;
	Result[2][2] =-f.z;
	Result[3][0] =-dot(s, eye);
	Result[3][1] =-dot(u, eye);
	Result[3][2] = dot(f, eye);
	return Result;
}

mat4 perspectiveRH_ZO(float fovy, float aspect, float zNear, float zFar)
{
	float tanHalfFovy = tan(fovy / 2.f);

	mat4 Result = mat4(0);
	Result[0][0] = 1.f / (aspect * tanHalfFovy);
	Result[1][1] = 1.f / (tanHalfFovy);
	Result[2][2] = zFar / (zNear - zFar);
	Result[2][3] = -1.f;
	Result[3][2] = -(zFar * zNear) / (zFar - zNear);
	return Result;
}

vec3 envmapColorConvolution(vec3 dir) 
{
    // the sample direction equals the hemisphere's orientation 
    vec3 normal = normalize(dir); // dir to cubemap texel pos = actual sample dir
  
  	Onb nonb = branchlessOnb(normal);
  
    vec3 irradiance = vec3(0.0);
    
	const uint samples = 4096;
	for(uint smpl = 0; smpl < samples; ++smpl){

		vec2 u = hammersley(smpl, samples); 
		
		vec3 L = cosineSampleHemisphere(u); 

		vec3 sampleVec = outOnbSpace(nonb, L);
		irradiance += texture(envmapSampler, sampleVec).rgb;
	}
	
	irradiance = irradiance * (1.0 / float(samples)) * PI;
  
	return irradiance; 
}                                                                                                                          
                 

void main() 
{
	// PERF:
	mat4 projInverse = inverse(perspectiveRH_ZO(1.5708f, 1.f, 1.f, 25.f));
	projInverse[1][1] *= -1;

	// PERF:
	mat4 viewInverses[] = {
		inverse(lookAtRH(vec3(0.0, 0.0, 0.0), vec3(1.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0))),   // right
		inverse(lookAtRH(vec3(0.0, 0.0, 0.0), vec3(-1.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0))),  // left
		inverse(lookAtRH(vec3(0.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0), vec3(0.0, 0.0, 1.0))),   // up
		inverse(lookAtRH(vec3(0.0, 0.0, 0.0), vec3(0.0, -1.0, 0.0), vec3(0.0, 0.0, -1.0))), // down
		inverse(lookAtRH(vec3(0.0, 0.0, 0.0), vec3(0.0, 0.0, -1.0), vec3(0.0, 1.0, 0.0))),  // front
		inverse(lookAtRH(vec3(0.0, 0.0, 0.0), vec3(0.0, 0.0, 1.0), vec3(0.0, 1.0, 0.0))),   // back
	};

	// for each face
	for (int f = 0; f < 6; ++f) {

		const vec2 pixelCenter = vec2(gl_GlobalInvocationID.xy) + vec2(0.5);
		const vec2 inUV        = pixelCenter / vec2(gl_NumWorkGroups.xy * gl_WorkGroupSize.xy);
		vec2       d           = inUV * 2.0 - 1.0;

		vec4 target    = projInverse * vec4(d.x, d.y, 1, 1);
		vec4 direction = viewInverses[f] * vec4(normalize(target.xyz), 0);

		vec3 accumColor = envmapColorConvolution(direction.xyz);

		imageStore(irradianceCube, ivec3(gl_GlobalInvocationID.xy, f), vec4(accumColor, 1.0));
	}
		
}
